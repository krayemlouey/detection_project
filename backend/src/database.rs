use sqlx::sqlite::SqlitePool;
use sqlx::Row;
use serde_json::{json, Value};
use chrono::Local;
use std::fs;

/// Initialise la connexion √† la base de donn√©es SQLite et cr√©e les tables si n√©cessaire
pub async fn init_database() -> Result<SqlitePool, sqlx::Error> {
    // Cr√©er le r√©pertoire de base de donn√©es s'il n'existe pas
    std::fs::create_dir_all("./data").map_err(|e| {
        eprintln!("‚ùå Erreur cr√©ation r√©pertoire: {}", e);
        sqlx::Error::Io(e)
    })?;
    
    let database_url = "sqlite:./data/detection.db";
    
    println!("üìä Connexion √† la base de donn√©es SQLite...");
    println!("üìÅ Chemin de la base: {}", database_url);
    
    let pool = SqlitePool::connect(database_url).await.map_err(|e| {
        eprintln!("‚ùå Erreur connexion base de donn√©es: {}", e);
        eprintln!("üí° V√©rifiez les permissions d'√©criture dans le r√©pertoire");
        e
    })?;

    create_tables(&pool).await?;

    println!("‚úÖ Base de donn√©es initialis√©e avec succ√®s");
    Ok(pool)
}

/// Cr√©e les tables n√©cessaires dans la base de donn√©es
async fn create_tables(pool: &SqlitePool) -> Result<(), sqlx::Error> {
    // Table des d√©tections individuelles
    sqlx::query(
        r#"
        CREATE TABLE IF NOT EXISTS detections (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            g_id TEXT NOT NULL,
            ref_count INTEGER NOT NULL DEFAULT 1,
            type TEXT NOT NULL,
            color TEXT NOT NULL,
            datetime TEXT NOT NULL,
            UNIQUE(g_id)
        )
        "#,
    )
    .execute(pool)
    .await?;

    // Table des statistiques journali√®res
    sqlx::query(
        r#"
        CREATE TABLE IF NOT EXISTS daily_stats (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            g_id TEXT NOT NULL,
            type TEXT NOT NULL,
            cadence INTEGER NOT NULL DEFAULT 0,
            day TEXT NOT NULL,
            UNIQUE(g_id, day)
        )
        "#,
    )
    .execute(pool)
    .await?;

    println!("üìã Tables cr√©√©es/v√©rifi√©es");
    Ok(())
}

/// Ins√®re une nouvelle d√©tection ou met √† jour si elle existe d√©j√† 
pub async fn insert_detection(
    pool: &SqlitePool,
    g_id: &str,
    object_type: &str,
    color: &str,
) -> Result<(), sqlx::Error> {
    let now = Local::now().format("%Y-%m-%d %H:%M:%S").to_string();
    let today = Local::now().format("%Y-%m-%d").to_string();

    let mut tx = pool.begin().await?;

    // Insert/update d√©tection
    sqlx::query(
        r#"
        INSERT INTO detections (g_id, ref_count, type, color, datetime)
        VALUES (?, 1, ?, ?, ?)
        ON CONFLICT(g_id) DO UPDATE SET
            ref_count = ref_count + 1,
            datetime = excluded.datetime
        "#,
    )
    .bind(g_id)
    .bind(object_type)
    .bind(color)
    .bind(&now)
    .execute(&mut *tx)
    .await?;

    // Insert/update statistiques journali√®res
    sqlx::query(
        r#"
        INSERT INTO daily_stats (g_id, type, cadence, day)
        VALUES (?, ?, 1, ?)
        ON CONFLICT(g_id, day) DO UPDATE SET
            cadence = cadence + 1
        "#,
    )
    .bind(g_id)
    .bind(object_type)
    .bind(&today)
    .execute(&mut *tx)
    .await?;

    tx.commit().await?;

    println!("üîç D√©tection ajout√©e: {} ({}) - {}", g_id, object_type, color);
    Ok(())
}

/// R√©cup√®re les d√©tections avec filtres optionnels sur la date
pub async fn get_detections(
    pool: &SqlitePool,
    from_date: Option<String>,
    to_date: Option<String>,
) -> Result<Vec<Value>, sqlx::Error> {
    let rows = match (&from_date, &to_date) {
        (Some(from), Some(to)) => {
            sqlx::query("SELECT g_id, ref_count, type, color, datetime FROM detections WHERE date(datetime) >= ? AND date(datetime) <= ? ORDER BY datetime DESC")
                .bind(from)
                .bind(to)
                .fetch_all(pool)
                .await?
        }
        (Some(from), None) => {
            sqlx::query("SELECT g_id, ref_count, type, color, datetime FROM detections WHERE date(datetime) >= ? ORDER BY datetime DESC")
                .bind(from)
                .fetch_all(pool)
                .await?
        }
        (None, Some(to)) => {
            sqlx::query("SELECT g_id, ref_count, type, color, datetime FROM detections WHERE date(datetime) <= ? ORDER BY datetime DESC")
                .bind(to)
                .fetch_all(pool)
                .await?
        }
        (None, None) => {
            sqlx::query("SELECT g_id, ref_count, type, color, datetime FROM detections ORDER BY datetime DESC")
                .fetch_all(pool)
                .await?
        }
    };

    let detections: Vec<Value> = rows
        .into_iter()
        .map(|row| {
            json!({
                "g_id": row.get::<String, _>("g_id"),
                "ref_count": row.get::<i64, _>("ref_count"),
                "type": row.get::<String, _>("type"),
                "color": row.get::<String, _>("color"),
                "datetime": row.get::<String, _>("datetime")
            })
        })
        .collect();

    Ok(detections)
}

/// R√©cup√®re les statistiques journali√®res et r√©centes
pub async fn get_daily_stats(pool: &SqlitePool) -> Result<Value, sqlx::Error> {
    let today = Local::now().format("%Y-%m-%d").to_string();

    let today_stats = sqlx::query(
        "SELECT type, SUM(cadence) as total FROM daily_stats WHERE day = ? GROUP BY type"
    )
    .bind(&today)
    .fetch_all(pool)
    .await?;

    let total_stats = sqlx::query(
        "SELECT type, SUM(cadence) as total FROM daily_stats GROUP BY type"
    )
    .fetch_all(pool)
    .await?;

    let recent_detections = sqlx::query(
        "SELECT g_id, type, color, datetime FROM detections ORDER BY datetime DESC LIMIT 10"
    )
    .fetch_all(pool)
    .await?;

    let today_data: Vec<Value> = today_stats
        .into_iter()
        .map(|row| json!({
            "type": row.get::<String, _>("type"),
            "count": row.get::<i64, _>("total")
        }))
        .collect();

    let total_data: Vec<Value> = total_stats
        .into_iter()
        .map(|row| json!({
            "type": row.get::<String, _>("type"),
            "count": row.get::<i64, _>("total")
        }))
        .collect();

    let recent_data: Vec<Value> = recent_detections
        .into_iter()
        .map(|row| json!({
            "g_id": row.get::<String, _>("g_id"),
            "type": row.get::<String, _>("type"),
            "color": row.get::<String, _>("color"),
            "datetime": row.get::<String, _>("datetime")
        }))
        .collect();

    Ok(json!({
        "today": today_data,
        "total": total_data,
        "recent": recent_data,
        "last_updated": Local::now().format("%Y-%m-%d %H:%M:%S").to_string()
    }))
}

/// Supprime les anciennes statistiques (maintenance)
#[allow(dead_code)]
pub async fn cleanup_old_data(pool: &SqlitePool, days_to_keep: i64) -> Result<(), sqlx::Error> {
    let cutoff_date = Local::now()
        .checked_sub_signed(chrono::Duration::days(days_to_keep))
        .unwrap()
        .format("%Y-%m-%d")
        .to_string();

    let deleted = sqlx::query("DELETE FROM daily_stats WHERE day < ?")
        .bind(&cutoff_date)
        .execute(pool)
        .await?;

    println!("üßπ Nettoyage: {} entr√©es supprim√©es", deleted.rows_affected());
    Ok(())
}